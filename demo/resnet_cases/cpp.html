

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>C++ Codes Explanation &mdash; SophonInference  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Python Codes Explanation" href="python.html" />
    <link rel="prev" title="Usage" href="usage.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> SophonInference
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../get_start/0_products.html">Sophon Products</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../get_start/1_crash_course.html">Crash Course</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../get_start/3_introduction.html">Introduction</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../0_preface.html">Preface</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../1_resnet50.html">Classification with Resnet</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="usage.html">Usage</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">C++ Codes Explanation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#case-0-simplest-case">Case 0: simplest case</a></li>
<li class="toctree-l3"><a class="reference internal" href="#case-1-multi-thread-implementation-of-case-0">Case 1: multi-thread implementation of case 0</a></li>
<li class="toctree-l3"><a class="reference internal" href="#case-2-multi-thread-with-multiple-models">Case 2: multi-thread with multiple models</a></li>
<li class="toctree-l3"><a class="reference internal" href="#case-3-multi-thread-with-multiple-tpus">Case 3: multi-thread with multiple TPUs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="python.html">Python Codes Explanation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../2_ssd.html">Detection with SSD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../3_yolov3.html">Detection with Yolov3</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_mtcnn.html">Detection with MTCNN</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../module/sail.html">SAIL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../module/sail_cpp.html">SAIL C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../module/sail_python.html">SAIL Python API</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">SophonInference</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../1_resnet50.html">Classification with Resnet</a> &raquo;</li>
        
      <li>C++ Codes Explanation</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/demo/resnet_cases/cpp.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="c-codes-explanation">
<h1>C++ Codes Explanation<a class="headerlink" href="#c-codes-explanation" title="Permalink to this headline">¶</a></h1>
<div class="section" id="case-0-simplest-case">
<h2>Case 0: simplest case<a class="headerlink" href="#case-0-simplest-case" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><dl class="docutils">
<dt>In case 0, we encapsulated a function named “inference”, as follows:</dt>
<dd><div class="first last highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">bool</span> <span class="nf">inference</span><span class="p">(</span>
<span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span> <span class="n">bmodel_path</span><span class="p">,</span>
<span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span> <span class="n">input_path</span><span class="p">,</span>
<span class="kt">int</span>                <span class="n">tpu_id</span><span class="p">,</span>
<span class="kt">int</span>                <span class="n">loops</span><span class="p">,</span>
<span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span> <span class="n">compare_path</span><span class="p">);</span>
</pre></div>
</div>
</dd>
</dl>
<p>The bmodel_path is the path of the bmodel of resnet50 which converted from a caffemodel of official resnet50.
We use this bmodel to initialize a sail::Engine instance, for futher inference.
We can get parameters, like graph_name, input_name and so on, from the sail::Engine instance.</p>
<blockquote>
<div><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">sail</span><span class="o">::</span><span class="n">Engine</span> <span class="n">engine</span><span class="p">(</span><span class="n">bmodel_path</span><span class="p">,</span> <span class="n">tpu_id</span><span class="p">,</span> <span class="n">sail</span><span class="o">::</span><span class="n">SYSIO</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">graph_name</span> <span class="o">=</span> <span class="n">engine</span><span class="p">.</span><span class="n">get_graph_names</span><span class="p">().</span><span class="n">front</span><span class="p">();</span>
<span class="k">auto</span> <span class="n">input_name</span> <span class="o">=</span> <span class="n">engine</span><span class="p">.</span><span class="n">get_input_names</span><span class="p">(</span><span class="n">graph_name</span><span class="p">).</span><span class="n">front</span><span class="p">();</span>
<span class="k">auto</span> <span class="n">output_name</span> <span class="o">=</span> <span class="n">engine</span><span class="p">.</span><span class="n">get_output_names</span><span class="p">(</span><span class="n">graph_name</span><span class="p">).</span><span class="n">front</span><span class="p">();</span>
<span class="k">auto</span> <span class="n">input_shape</span> <span class="o">=</span> <span class="n">engine</span><span class="p">.</span><span class="n">get_input_shape</span><span class="p">(</span><span class="n">graph_name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">output_shape</span> <span class="o">=</span> <span class="n">engine</span><span class="p">.</span><span class="n">get_output_shape</span><span class="p">(</span><span class="n">graph_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">in_dtype</span> <span class="o">=</span> <span class="n">engine</span><span class="p">.</span><span class="n">get_input_dtype</span><span class="p">(</span><span class="n">graph_name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">out_dtype</span> <span class="o">=</span> <span class="n">engine</span><span class="p">.</span><span class="n">get_output_dtype</span><span class="p">(</span><span class="n">graph_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">);</span>
</pre></div>
</div>
</div></blockquote>
<p>The input_path is the path of an arbitary image.
We supplied ready-made bmodels and images, the script ${sophon-inference}/tools/download.py can help you get them.</p>
<p>The tpu_id indicates which TPU you want to use.
default value of tpu_id is 0, means using first TPU on your PC or Server.</p>
<p>The loops determines how many times you will run the bmodel.
Let’s see what happened in the loop:</p>
<blockquote>
<div><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">loops</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// read image</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">frame</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">imread</span><span class="p">(</span><span class="n">input_path</span><span class="p">);</span>
  <span class="c1">// preprocess</span>
  <span class="n">preprocessor</span><span class="p">.</span><span class="n">process</span><span class="p">(</span><span class="n">input</span><span class="p">,</span> <span class="n">frame</span><span class="p">);</span>
  <span class="c1">// scale input data if input data type is int8 or uint8</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">in_dtype</span> <span class="o">!=</span> <span class="n">BM_FLOAT32</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">engine</span><span class="p">.</span><span class="n">scale_input_tensor</span><span class="p">(</span><span class="n">graph_name</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">input</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="c1">// inference</span>
  <span class="n">engine</span><span class="p">.</span><span class="n">process</span><span class="p">(</span><span class="n">graph_name</span><span class="p">);</span>
  <span class="c1">// scale output data if input data type is int8 or uint8</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">out_dtype</span> <span class="o">!=</span> <span class="n">BM_FLOAT32</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">engine</span><span class="p">.</span><span class="n">scale_output_tensor</span><span class="p">(</span><span class="n">graph_name</span><span class="p">,</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">output</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="c1">// postprocess</span>
  <span class="k">auto</span> <span class="n">result</span> <span class="o">=</span> <span class="n">postprocessor</span><span class="p">.</span><span class="n">process</span><span class="p">(</span><span class="n">output</span><span class="p">);</span>
  <span class="c1">// print result</span>
  <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="nl">item</span> <span class="p">:</span> <span class="n">result</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">spdlog</span><span class="o">::</span><span class="n">info</span><span class="p">(</span><span class="s">&quot;Top 5 of loop {}: [{}]&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">fmt</span><span class="o">::</span><span class="n">join</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="s">&quot;, &quot;</span><span class="p">));</span>
    <span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">postprocessor</span><span class="p">.</span><span class="n">compare</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span>
        <span class="p">(</span><span class="n">out_dtype</span> <span class="o">==</span> <span class="n">BM_FLOAT32</span><span class="p">)</span> <span class="o">?</span> <span class="s">&quot;fp32&quot;</span> <span class="o">:</span> <span class="s">&quot;int8&quot;</span><span class="p">))</span> <span class="p">{</span>
      <span class="n">status</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
      <span class="k">break</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">status</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">break</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
<p>As the codes shown, in each loop, we read an image from a string path to get a cv::Mat instance.
Then, we do some preprocessing on the image data, like resizing.
After preprocessing, we will scale the values of the data depends on its data type,
this procedure is required by the int8 mode,
which data should be converted from fp32 to int8 by a scale factor.
Due to the pointer of the input tensor data was already stored in the SAIL::Engine instance,
we only need to use the “engine.process(graph_name)” to drive bmodel to do inference.
And at last, postprocessing the output tensor which data pointer was also stored in the SAIL::Engine instance.
Apparently, we can execute the inference pipeline(the loop) shown above, for many times, with feeding different images.</p>
</div></blockquote>
</div>
<div class="section" id="case-1-multi-thread-implementation-of-case-0">
<h2>Case 1: multi-thread implementation of case 0<a class="headerlink" href="#case-1-multi-thread-implementation-of-case-0" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>In case 1, we will show the multi-thread programming mode of SAIL::Engine.
Simplely, one bmodel was loaded by one SAIL::Engine instance, while input/output tensors are managed outside this SAIL::Engine instance in different threads.</p>
<dl class="docutils">
<dt>We loaded the bmodel into SAIL::Engine instance after constucor, not in the constructor:</dt>
<dd><div class="first last highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// init Engine</span>
<span class="n">sail</span><span class="o">::</span><span class="n">Engine</span> <span class="n">engine</span><span class="p">(</span><span class="n">tpu_id</span><span class="p">);</span>
<span class="c1">// load bmodel without builtin input and output tensors</span>
<span class="c1">// each thread manage its input and output tensors</span>
<span class="kt">int</span> <span class="n">ret</span> <span class="o">=</span> <span class="n">engine</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">bmodel_path</span><span class="p">);</span>
</pre></div>
</div>
</dd>
</dl>
<p>In each thread, we seperately managed the input and output tensors.
While in case 0, these tensors were managed automatically in the SAIL::Engine instance.</p>
<blockquote>
<div><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// get handle to create input and output tensors</span>
<span class="n">sail</span><span class="o">::</span><span class="n">Handle</span> <span class="n">handle</span> <span class="o">=</span> <span class="n">engine</span><span class="o">-&gt;</span><span class="n">get_handle</span><span class="p">();</span>
<span class="c1">// allocate input and output tensors with both system and device memory</span>
<span class="n">sail</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">in</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">,</span> <span class="n">in_dtype</span><span class="p">,</span> <span class="nb">true</span><span class="p">,</span> <span class="nb">true</span><span class="p">);</span>
<span class="n">sail</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">out</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">,</span> <span class="n">out_dtype</span><span class="p">,</span> <span class="nb">true</span><span class="p">,</span> <span class="nb">true</span><span class="p">);</span>
<span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span> <span class="n">sail</span><span class="o">::</span><span class="n">Tensor</span><span class="o">*&gt;</span> <span class="n">input_tensors</span> <span class="o">=</span> <span class="p">{{</span><span class="n">input_name</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">in</span><span class="p">}};</span>
<span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span> <span class="n">sail</span><span class="o">::</span><span class="n">Tensor</span><span class="o">*&gt;</span> <span class="n">output_tensors</span> <span class="o">=</span> <span class="p">{{</span><span class="n">output_name</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">out</span><span class="p">}};</span>
</pre></div>
</div>
</div></blockquote>
</div></blockquote>
</div>
<div class="section" id="case-2-multi-thread-with-multiple-models">
<h2>Case 2: multi-thread with multiple models<a class="headerlink" href="#case-2-multi-thread-with-multiple-models" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>In case 2, we will load different bmodels into a SAIL::Engine instance for each inference thread.
The codes in case 2 is a little different with that in case 1.
Just place the “SAIL::Engine.load(bmodel) function” into each thread is OK.
In this case, we used a loading thread to finish it.</p>
<blockquote>
<div><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cm">/**</span>
<span class="cm">* @brief Load a bmodel.</span>
<span class="cm">*</span>
<span class="cm">* @param thread_id   Thread id</span>
<span class="cm">* @param engine      Pointer to an Engine instance</span>
<span class="cm">* @param bmodel_path Path to bmodel</span>
<span class="cm">*/</span>
<span class="kt">void</span> <span class="nf">thread_load</span><span class="p">(</span>
     <span class="kt">int</span>                <span class="n">thread_id</span><span class="p">,</span>
     <span class="n">sail</span><span class="o">::</span><span class="n">Engine</span><span class="o">*</span>      <span class="n">engine</span><span class="p">,</span>
     <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span> <span class="n">bmodel_path</span><span class="p">)</span> <span class="p">{</span>
       <span class="kt">int</span> <span class="n">ret</span> <span class="o">=</span> <span class="n">engine</span><span class="o">-&gt;</span><span class="n">load</span><span class="p">(</span><span class="n">bmodel_path</span><span class="p">);</span>
       <span class="k">if</span> <span class="p">(</span><span class="n">ret</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
         <span class="k">auto</span> <span class="n">graph_name</span> <span class="o">=</span> <span class="n">engine</span><span class="o">-&gt;</span><span class="n">get_graph_names</span><span class="p">().</span><span class="n">back</span><span class="p">();</span>
         <span class="n">spdlog</span><span class="o">::</span><span class="n">info</span><span class="p">(</span><span class="s">&quot;Thread {} load {} successfully.&quot;</span><span class="p">,</span> <span class="n">thread_id</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">);</span>
       <span class="p">}</span>
     <span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
<p>Other codes are almost the same with case 1.</p>
</div></blockquote>
</div>
<div class="section" id="case-3-multi-thread-with-multiple-tpus">
<h2>Case 3: multi-thread with multiple TPUs<a class="headerlink" href="#case-3-multi-thread-with-multiple-tpus" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>In Case 3, we will exploit multiple TPUs to do inference.
While the SAIL:Engine instance is bound to device,
we should initialize multiple SAIL::Engine instances for each TPU.</p>
<blockquote>
<div><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// init Engine to load bmodel and allocate input and output tensors</span>
<span class="c1">// one engine for one TPU</span>
<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">sail</span><span class="o">::</span><span class="n">Engine</span><span class="o">*&gt;</span> <span class="n">engines</span><span class="p">(</span><span class="n">thread_num</span><span class="p">,</span> <span class="k">nullptr</span><span class="p">);</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">thread_num</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">engines</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="k">new</span> <span class="n">sail</span><span class="o">::</span><span class="n">Engine</span><span class="p">(</span><span class="n">bmodel_path</span><span class="p">,</span> <span class="n">tpu_ids</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">sail</span><span class="o">::</span><span class="n">SYSIO</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
<p>Other codes are almost the same with case 1.</p>
</div></blockquote>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="python.html" class="btn btn-neutral float-right" title="Python Codes Explanation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="usage.html" class="btn btn-neutral float-left" title="Usage" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Sophon

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>